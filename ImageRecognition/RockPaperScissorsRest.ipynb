{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bf513ef",
   "metadata": {},
   "source": [
    "# Classification of images\n",
    "\n",
    "Given are images that represent the hand gestures of the game \"paper, rock, scissors\" and that are stored in the respective\n",
    "folders. In an additionally folder random images (that do not correspond to one of these gestures) are stored.\n",
    "A classification model is to be build that classifies an image to one of the four labels \"paper\", \"rock\", \"scissors\" or \"rest\".\n",
    "\n",
    "This project was created by Julian Kartte. For a more detailed description check out my [github](https://github.com/juliankartte/showroom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8be16ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\.conda\\envs\\test\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import os\n",
    "import csv\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools\n",
    "import json\n",
    "from tensorflow.keras.constraints import max_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca07158",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905ade98",
   "metadata": {},
   "source": [
    "**List of included parameters**:\n",
    "- **x_scale**: Number of pixels on the x-axis\n",
    "- **y_scale**: Number of pixels on the y-axis\n",
    "- **validation_split**: Ration of data in validation set\n",
    "\n",
    "\n",
    "- **use_data_preprocessing**: Doubles the amount of input-data bei rotating them by 180 degrees\n",
    "- **use_data_augmentation**: Use data augmentation in keras ImageGenerators\n",
    "\n",
    "\n",
    "- **modelname**: select one of the following models\n",
    " - FarahAmalia (acc=96): https://medium.com/geekculture/rock-paper-scissors-image-classification-using-cnn-eefe4569b415\n",
    " - Devakumar (acc=90): https://www.kaggle.com/code/imdevskp/rock-paper-scissors-image-classification-using-cnn/notebook\n",
    " - Aditya (acc=100): https://www.kaggle.com/code/recursion17/rockpaperscissors-100-accuracy\n",
    " - Custom: custom model\n",
    " - Custom_constraints: custom model with constraints\n",
    " \n",
    " \n",
    "- **optimizer**: select one of the following optimizers\n",
    " - Adam\n",
    " - Adadelta\n",
    " - Adagrad\n",
    " - RMSprop\n",
    " - SGD\n",
    "\n",
    "\n",
    "- **loss_function**: sets the loss_function of the model\n",
    "- **epochs**: number of epochs\n",
    "- **batch_size**: sets the batch size\n",
    "- **dropout_ration**: sets the dropout_ratio of dropout_layers\n",
    "\n",
    "\n",
    "- **learning_rate_reduction**: Determines whether to use learning rate reduction on plateau or not.\n",
    "- **learning_rate_monitor**: monitored quantity for learning_rate_reduction\n",
    "- **learning_rate_patience**: number of epochs to wait\n",
    "- **learning_rate_verbose**: update messages\n",
    "- **learning_rate_factor**: ration of reduction\n",
    "- **learnint_rate_start_lr**: sets starting learning rate\n",
    "- **learning_rate_min_lr**: minimal learning rate\n",
    "\n",
    "\n",
    "- **early_stopping**: Use early stopping or not\n",
    "- **early_stopping_monitor**: monitored quantity\n",
    "- **early_stopping_min_delta**: minimal difference between quantity needed to be seen as a decrease\n",
    "- **early_stopping_patience**: number of rounds waiting since last decrease before stopping\n",
    "- **early_stopping_verbose**: output messages\n",
    "- **early_stopping_restore_best_weights**: restore best weights after early stopping\n",
    "\n",
    "\n",
    "- **use_kaggle_data**: uses provided data\n",
    "- **use_grayscaled_data**: uses provided data turned into grayscale\n",
    "- **use_grayscaled_augmented_data**: uses augmented data turned into grayscale\n",
    "- **use_rest_class**: uses rest class or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "021bde93",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_config = {\n",
    "    'x_scale': [30], # 60, 120\n",
    "    'y_scale': [20], # 40, 80\n",
    "    'validation_split': [0.2],\n",
    "    \n",
    "    'use_data_augmentation': [True],\n",
    "    \n",
    "    'modelname': ['Custom_constraints'], #'Custom', 'Aditya', 'FarahAmalia', 'Devakumar'],\n",
    "    'optimizer': [\n",
    "        tf.keras.optimizers.Adam(),\n",
    "        #tf.keras.optimizers.Adadelta(),\n",
    "        #tf.keras.optimizers.Adagrad(),\n",
    "        #tf.keras.optimizers.Adamax(),\n",
    "        #tf.keras.optimizers.RMSprop(),\n",
    "        #tf.keras.optimizers.SGD()\n",
    "        ],\n",
    "    \n",
    "    'loss_function': ['categorical_crossentropy'],\n",
    "    'epochs': [50],\n",
    "    'batch_size': [16],\n",
    "    'dropout_ratio': [0.3],\n",
    "\n",
    "    'learning_rate_reduction': [True],\n",
    "    'learning_rate_monitor': ['val_categorical_accuracy'],\n",
    "    'learning_rate_patience': [2],\n",
    "    'learning_rate_verbose': [1],\n",
    "    'learning_rate_factor': [0.25],\n",
    "    'learning_rate_start_lr': [0.001],\n",
    "    'learning_rate_min_lr': [0.000003],\n",
    "\n",
    "    'early_stopping': [True],\n",
    "    'early_stopping_monitor': ['val_categorical_accuracy'], #'val_loss'],\n",
    "    'early_stopping_min_delta': [0],\n",
    "    'early_stopping_patience': [10],\n",
    "    'early_stopping_verbose': [1],\n",
    "    'early_stopping_restore_best_weights': [True],\n",
    "\n",
    "    'use_grayscaled_data': [False],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264d0d4c",
   "metadata": {},
   "source": [
    "# Data augmentation and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14275b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(input_dict):\n",
    "    \"\"\"\n",
    "    Loads the images from the path './Traindata' according to the configuration in gs_config.\n",
    "    Returns train_generator, validation_generator.\n",
    "    \"\"\"\n",
    "    \n",
    "    x_scale: int = input_dict['x_scale']\n",
    "    y_scale: int = input_dict['y_scale']\n",
    "    batch_size: int = input_dict['batch_size']\n",
    "    data_augmentation: bool = input_dict['use_data_augmentation']\n",
    "    validation_split: float = input_dict['validation_split']\n",
    "    use_grayscaled_data : bool = input_dict['use_grayscaled_data']\n",
    "        \n",
    "    if use_grayscaled_data:\n",
    "        color_mode = 'grayscale'\n",
    "    else:\n",
    "        color_mode = 'rgb'\n",
    "\n",
    "    if data_augmentation :\n",
    "        datagen = ImageDataGenerator(rescale = 1.0/255,\n",
    "                                     rotation_range = 20,\n",
    "                                     width_shift_range = 0.2,\n",
    "                                     height_shift_range = 0.2,\n",
    "                                     shear_range = 0.2,\n",
    "                                     zoom_range = 0.2,\n",
    "                                     horizontal_flip = True,\n",
    "                                     fill_mode = 'nearest',\n",
    "                                     validation_split = validation_split\n",
    "                              )\n",
    "        valgen = ImageDataGenerator(rescale = 1.0/255,\n",
    "                                    validation_split = validation_split)\n",
    "    else:\n",
    "        datagen = ImageDataGenerator(rescale = 1.0/255,\n",
    "                                     validation_split = validation_split\n",
    "                                    )\n",
    "        valgen = ImageDataGenerator(rescale = 1.0/255,\n",
    "                                     validation_split = validation_split\n",
    "                                   )\n",
    "\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "            './Traindata',\n",
    "            target_size=(x_scale, y_scale),\n",
    "            color_mode = color_mode,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            class_mode='categorical',\n",
    "            subset='training',\n",
    "    )\n",
    "    \n",
    "    validation_generator = valgen.flow_from_directory(\n",
    "            './Traindata', \n",
    "            target_size=(x_scale, y_scale),\n",
    "            color_mode = color_mode,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            class_mode='categorical',\n",
    "            subset='validation')\n",
    "\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2369b696",
   "metadata": {},
   "source": [
    "# Creating and fitting the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62f1fe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(optimizer, labels_count, input_dict):    \n",
    "    \"\"\"\n",
    "    Builds a model according to the specification in the current iteration input_dict of gs_config.\n",
    "    Returns the built model.\n",
    "    \"\"\"\n",
    "    \n",
    "    modelname = input_dict['modelname']\n",
    "    loss_function = input_dict['loss_function']\n",
    "    x_scale = input_dict['x_scale']\n",
    "    y_scale = input_dict['y_scale']\n",
    "    lr_start = input_dict['learning_rate_start_lr']\n",
    "    dropout_ratio = input_dict['dropout_ratio']\n",
    "    \n",
    "    if input_dict['use_grayscaled_data']:\n",
    "        color_layer = 1\n",
    "    else:\n",
    "        color_layer = 3\n",
    "    \n",
    "    if modelname == 'FarahAmalia':\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(64, (3,3), activation=tf.nn.relu, input_shape=(x_scale, y_scale, color_layer)),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "            tf.keras.layers.Conv2D(64, (3,3), activation=tf.nn.relu, padding = 'Same'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "            tf.keras.layers.Conv2D(128, (3,3), activation=tf.nn.relu, padding = 'Same'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "            tf.keras.layers.Flatten(),\n",
    "\n",
    "            tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(labels_count, activation = tf.nn.softmax),\n",
    "        ])\n",
    "        \n",
    "    elif modelname == 'Devakumar':\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(x_scale, y_scale, color_layer)),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(labels_count, activation='sigmoid'),\n",
    "        ])\n",
    "        \n",
    "    elif modelname == 'Aditya':\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(64, (5,5), activation=tf.nn.relu, input_shape=(x_scale, y_scale, color_layer)),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "            tf.keras.layers.Conv2D(64, (3,3), activation=tf.nn.relu, padding = 'Same'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "            tf.keras.layers.Conv2D(128, (3,3), activation=tf.nn.relu, padding = 'Same'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "            tf.keras.layers.Flatten(),\n",
    "\n",
    "            tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(labels_count, activation = tf.nn.softmax)\n",
    "        ])\n",
    "\n",
    "    elif modelname == 'Custom':\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(64, (5,5), activation=tf.nn.relu, input_shape=(x_scale, y_scale, color_layer)),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "            tf.keras.layers.Conv2D(64, (3,3), activation=tf.nn.relu, padding = 'Same'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "            tf.keras.layers.Conv2D(128, (3,3), activation=tf.nn.relu, padding = 'Same'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "            tf.keras.layers.Flatten(),\n",
    "\n",
    "            tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(labels_count, activation = tf.nn.softmax)\n",
    "        ])\n",
    "        \n",
    "    elif modelname == 'Custom_constraints':\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(64, (3,3), activation=tf.nn.relu, kernel_constraint=max_norm(3), \n",
    "                                   input_shape=(x_scale, y_scale, color_layer)),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dropout(dropout_ratio),\n",
    "\n",
    "            tf.keras.layers.Conv2D(64, (3,3), activation=tf.nn.relu, padding = 'Same', kernel_constraint=max_norm(3)),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Dropout(dropout_ratio),\n",
    "\n",
    "            tf.keras.layers.Conv2D(128, (3,3), activation=tf.nn.relu, padding = 'Same', kernel_constraint=max_norm(3)),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Dropout(dropout_ratio),\n",
    "\n",
    "            tf.keras.layers.Flatten(),\n",
    "\n",
    "            tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(labels_count, activation = tf.nn.softmax),\n",
    "        ])\n",
    "    \n",
    "    temp_metrics = [\n",
    "        tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy'),\n",
    "        tf.keras.metrics.BinaryAccuracy(name='binary_accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    "\n",
    "    if type(optimizer) == type(tf.keras.optimizers.Adam()):\n",
    "        temp_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_start)\n",
    "    elif type(optimizer) == type(tf.keras.optimizers.Adamax()):\n",
    "        temp_optimizer = tf.keras.optimizers.Adamax(learning_rate=lr_start)\n",
    "    elif type(optimizer) == type(tf.keras.optimizers.Adagrad()):\n",
    "        temp_optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr_start)\n",
    "    elif type(optimizer) == type(tf.keras.optimizers.Adadelta()):\n",
    "        temp_optimizer = tf.keras.optimizers.Adadelta(learning_rate=lr_start)\n",
    "    elif type(optimizer) == type(tf.keras.optimizers.Nadam()):\n",
    "        temp_optimizer = tf.keras.optimizers.Nadam(learning_rate=lr_start)\n",
    "    elif type(optimizer) == type(tf.keras.optimizers.RMSprop()):\n",
    "        temp_optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr_start)\n",
    "    elif type(optimizer) == type(tf.keras.optimizers.SGD()):\n",
    "        temp_optimizer = tf.keras.optimizers.SGD(learning_rate=lr_start)\n",
    "    else:\n",
    "        print('ERROR in get_model!')\n",
    "        return None\n",
    "    model.compile(loss=loss_function, optimizer=temp_optimizer, metrics=[temp_metrics], experimental_run_tf_function=False)\n",
    "    \n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def fit_model(model, train_generator, validation_generator, iter_dict):\n",
    "    \"\"\"\n",
    "    Fits the model to the train_generator and validates on the validation_generator.\n",
    "    Returns the history of the model and the stopped epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    callback_list = None\n",
    "\n",
    "    if iter_dict['learning_rate_reduction']:\n",
    "        learning_rate_reduction = ReduceLROnPlateau(monitor=iter_dict['learning_rate_monitor'],\n",
    "                                            patience=iter_dict['learning_rate_patience'],\n",
    "                                            verbose=iter_dict['learning_rate_verbose'],\n",
    "                                            factor=iter_dict['learning_rate_factor'],\n",
    "                                            min_lr=iter_dict['learning_rate_min_lr'])\n",
    "        if callback_list == None:\n",
    "            callback_list = [learning_rate_reduction]\n",
    "        else:\n",
    "            callback_list.append(learning_rate_reduction)\n",
    "        \n",
    "    if iter_dict['early_stopping']:\n",
    "        early_stopping = EarlyStopping(monitor=iter_dict['early_stopping_monitor'],\n",
    "                                       min_delta=iter_dict['early_stopping_min_delta'], \n",
    "                                       patience=iter_dict['early_stopping_patience'], \n",
    "                                       verbose=iter_dict['early_stopping_verbose'], \n",
    "                                       restore_best_weights=iter_dict['early_stopping_restore_best_weights'])\n",
    "        if callback_list == None:\n",
    "            callback_list = [early_stopping]\n",
    "        else:\n",
    "            callback_list.append(early_stopping)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=iter_dict['epochs'],\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=callback_list)\n",
    "    \n",
    "    if iter_dict['early_stopping']:\n",
    "        return history, early_stopping\n",
    "    else:\n",
    "        return history, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bca435d",
   "metadata": {},
   "source": [
    "# Grid Search\n",
    "\n",
    "- get_permutations creates all possible permutations of gs_config. Returns a list of tuples T. Every T consists of tuples t of size 2. The first element of t is the key of the dictionaries and the second element is the value of the dictionaries. See the following example:\n",
    "\n",
    "    `[(('modelname', 'FarahAmalia'),\n",
    "    ('optimizer', 'Adam'),\n",
    "    ('loss_function', 'categorical_crossentropy'),\n",
    "    ('metric', 'acc'),\n",
    "    ('epochs', 10),\n",
    "    ('batch_size', 32)), ...]`\n",
    "\n",
    "\n",
    "- Function grid_search iterates through all tuples T. In every iteration one we take on T and turn it into a dictionary, that gets returned at the end of the function. One dictionary of this kind includes all the parameters and the corresponding values for one run of grid_search. Example:\n",
    "\n",
    "    `{'modelname': 'FarahAmalia',\n",
    "     'optimizer': 'Adam',\n",
    "     'loss_function': 'categorical_crossentropy',\n",
    "     'metric': 'acc',\n",
    "     'epochs': 10,\n",
    "     'batch_size': 32}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1da1182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_permutations(dictionary):\n",
    "    '''\n",
    "    Creates all permutations of the input dictionary. \n",
    "    Returns these iterations as a list of tupels of tupels.\n",
    "    '''\n",
    "    temp_dict = {}\n",
    "    \n",
    "    for key, value in dictionary.items():\n",
    "        temp_dict[key] = [(key, v) for v in value]\n",
    "    \n",
    "    elements = list(temp_dict.values())\n",
    "        \n",
    "    return list(itertools.product(*elements))\n",
    "\n",
    "def grid_search():\n",
    "    \"\"\"\n",
    "    For every iteration: get the data and the model corresponding to the settings in that iteration of gs_config.\n",
    "    Fits the model and returns:\n",
    "    - best_model_dict: dictionary of best models for different metrics\n",
    "    - model_result: results of every model\n",
    "    \"\"\"\n",
    "    \n",
    "    best_model_dict = {\n",
    "        'val_loss': None,\n",
    "        'val_categorical_accuracy': None,\n",
    "        'val_binary_accuracy': None,\n",
    "        'val_precision': None,\n",
    "        'val_recall': None\n",
    "    }\n",
    "        \n",
    "    permutations = get_permutations(gs_config)\n",
    "    labels = os.listdir('./Traindata')\n",
    "\n",
    "    model_results = []\n",
    "    for p in permutations:\n",
    "        iter_dict = dict(p)\n",
    "        print('\\nActual permutation:')\n",
    "        print(json.dumps(str(iter_dict), indent=1))\n",
    "        train_gen, val_gen = get_data(iter_dict)\n",
    "\n",
    "        default_optimizer = iter_dict['optimizer']\n",
    "        model = get_model(optimizer=default_optimizer, labels_count=len(labels), input_dict=iter_dict)\n",
    "        history, early_stopping = fit_model(model, train_gen, val_gen, iter_dict)\n",
    "\n",
    "        # save best models\n",
    "        for key in best_model_dict.keys():\n",
    "            if key == 'val_loss' and (best_model_dict[key] is None or min(history.history[key]) < min(best_model_dict[key].history.history[key])):\n",
    "                    best_model_dict[key] = model\n",
    "            elif best_model_dict[key] is None or max(history.history[key]) > max(best_model_dict[key].history.history[key]):\n",
    "                    best_model_dict[key] = model\n",
    "        model_results.append((iter_dict, history, early_stopping))\n",
    "       \n",
    "    return best_model_dict, model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13616fe9",
   "metadata": {},
   "source": [
    "# Running grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e13e6f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actual permutation:\n",
      "\"{'x_scale': 30, 'y_scale': 20, 'validation_split': 0.2, 'use_data_augmentation': True, 'modelname': 'Custom_constraints', 'optimizer': <keras.optimizers.optimizer_v2.adam.Adam object at 0x0000020225628EB0>, 'loss_function': 'categorical_crossentropy', 'epochs': 50, 'batch_size': 16, 'dropout_ratio': 0.3, 'learning_rate_reduction': True, 'learning_rate_monitor': 'val_categorical_accuracy', 'learning_rate_patience': 2, 'learning_rate_verbose': 1, 'learning_rate_factor': 0.25, 'learning_rate_start_lr': 0.001, 'learning_rate_min_lr': 3e-06, 'early_stopping': True, 'early_stopping_monitor': 'val_categorical_accuracy', 'early_stopping_min_delta': 0, 'early_stopping_patience': 10, 'early_stopping_verbose': 1, 'early_stopping_restore_best_weights': True, 'use_grayscaled_data': False}\"\n",
      "Found 8095 images belonging to 4 classes.\n",
      "Found 2021 images belonging to 4 classes.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 18, 64)        1792      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 18, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 28, 18, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 18, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 9, 64)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 14, 9, 64)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 9, 128)        73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 7, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3584)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               917760    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,031,620\n",
      "Trainable params: 1,031,492\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      " 17/506 [>.............................] - ETA: 38s - loss: 2.5823 - categorical_accuracy: 0.2500 - binary_accuracy: 0.6976 - precision: 0.1935 - recall: 0.0662"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4352/1325031608.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_models\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4352/1125587822.py\u001b[0m in \u001b[0;36mgrid_search\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mdefault_optimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'optimizer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miter_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# save best models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4352/569994619.py\u001b[0m in \u001b[0;36mfit_model\u001b[1;34m(model, train_generator, validation_generator, iter_dict)\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0mcallback_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m     history = model.fit(\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miter_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'epochs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\test\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\test\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\test\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\test\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\test\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\test\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2451\u001b[0m       (graph_function,\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\test\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1860\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\.conda\\envs\\test\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\test\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_models, results  = grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc1205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e48607c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
